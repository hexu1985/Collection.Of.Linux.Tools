<!DOCTYPE html>
<!-- saved from url=(0036)https://onnxruntime.ai/docs/install/ -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">  <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="./Install ONNX Runtime _ onnxruntime_files/just-the-docs-default.css"> <link rel="stylesheet" href="./Install ONNX Runtime _ onnxruntime_files/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet" disabled=""> <style id="jtd-nav-activation"> .site-nav > ul.nav-list:first-child > li:not(:nth-child(2)) > a, .site-nav > ul.nav-list:first-child > li > ul > li > a, .site-nav > ul.nav-list:first-child > li > ul > li > ul > li > a { background-image: none; } .site-nav > ul.nav-list:not(:first-child) a, .site-nav li.external a { background-image: none; } .site-nav > ul.nav-list:first-child > li:nth-child(2) > a { font-weight: 600; text-decoration: none; }.site-nav > ul.nav-list:first-child > li:nth-child(2) > button svg { transform: rotate(-90deg); }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(2) > ul.nav-list { display: block; } </style> <script type="text/javascript" async="" src="./Install ONNX Runtime _ onnxruntime_files/analytics.js"></script><script type="text/javascript" async="" src="./Install ONNX Runtime _ onnxruntime_files/js"></script><script async="" src="./Install ONNX Runtime _ onnxruntime_files/js(1)"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-156955408-1'); </script> <script src="./Install ONNX Runtime _ onnxruntime_files/lunr.min.js"></script> <script src="./Install ONNX Runtime _ onnxruntime_files/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="https://onnxruntime.ai/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Install ONNX Runtime | onnxruntime</title> <meta name="generator" content="Jekyll v3.9.5"> <meta property="og:title" content="Install ONNX Runtime"> <meta property="og:locale" content="en_US"> <meta name="description" content="Instructions to install ONNX Runtime on your target platform in your environment"> <meta property="og:description" content="Instructions to install ONNX Runtime on your target platform in your environment"> <link rel="canonical" href="https://onnxruntime.ai/docs/install/"> <meta property="og:url" content="https://onnxruntime.ai/docs/install/"> <meta property="og:site_name" content="onnxruntime"> <meta property="og:type" content="website"> <meta name="twitter:card" content="summary"> <meta property="twitter:title" content="Install ONNX Runtime"> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"Instructions to install ONNX Runtime on your target platform in your environment","headline":"Install ONNX Runtime","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://onnxruntime.ai/images/ONNX-Runtime-logo.svg"}},"url":"https://onnxruntime.ai/docs/install/"}</script> <!-- End Jekyll SEO tag --> <meta property="og:image" content="/images/logos/onnxruntime/ORT_icon_for_light_bg.png"> <script type="text/javascript" src="./Install ONNX Runtime _ onnxruntime_files/ms.analytics-web-3.min.js"></script> <script type="text/javascript"> const config = { instrumentationKey: '360b0e675e0044398fd28c8bdf711b8e-1fe5434d-ee99-4837-99cc-a3a16462d82d-7262', channelConfiguration: { eventsLimitInMem: 50 }, propertyConfiguration: { env: 'PROD' }, webAnalyticsConfiguration: { autoCapture: { scroll: true, pageView: true, onLoad: true, onUnload: true, click: true, resize: true, jsError: true } } }; const analytics = new oneDS.ApplicationInsights(); analytics.initialize(config, []); </script> </head> <body> <a class="skip-to-main" href="https://onnxruntime.ai/docs/install/#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"></path> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"></path> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"></path> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"></path> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="https://onnxruntime.ai/" class="site-title lh-tight"> <div class="site-logo" role="img" aria-label="onnxruntime"></div> </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/" class="nav-list-link">ONNX Runtime</a></li><li class="nav-list-item active"><a class="nav-list-link active">Install ONNX Runtime</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Get Started category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/get-started/" class="nav-list-link">Get Started</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-python.html" class="nav-list-link">Python</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-cpp.html" class="nav-list-link">C++</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-c.html" class="nav-list-link">C</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-csharp.html" class="nav-list-link">C#</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-java.html" class="nav-list-link">Java</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in JavaScript category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/get-started/with-javascript/" class="nav-list-link">JavaScript</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/with-javascript/web.html" class="nav-list-link">Web</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/with-javascript/node.html" class="nav-list-link">Node.js binding</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/with-javascript/react-native.html" class="nav-list-link">React Native</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-obj-c.html" class="nav-list-link">Objective-C</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/community-projects.html" class="nav-list-link">Julia and Ruby APIs</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-windows.html" class="nav-list-link">Windows</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-mobile.html" class="nav-list-link">Mobile</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/training-on-device.html" class="nav-list-link">On-Device Training</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/training-pytorch.html" class="nav-list-link">Large Model Training</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/" class="nav-list-link">Tutorials</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/api-basics.html" class="nav-list-link">API Basics</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Accelerate PyTorch category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/" class="nav-list-link">Accelerate PyTorch</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/pytorch.html" class="nav-list-link">PyTorch Inference</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/resnet-inferencing.html" class="nav-list-link">Inference on multiple targets</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/ort-training.html" class="nav-list-link">Accelerate PyTorch Training</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/tensorflow.html" class="nav-list-link">Accelerate TensorFlow</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/huggingface.html" class="nav-list-link">Accelerate Hugging Face</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/azureml.html" class="nav-list-link">Deploy on AzureML</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Deploy on mobile category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/mobile/" class="nav-list-link">Deploy on mobile</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/pose-detection.html" class="nav-list-link">Object detection and pose estimation with YOLOv8</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/deploy-android.html" class="nav-list-link">Mobile image recognition on Android</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/superres.html" class="nav-list-link">Improve image resolution on mobile</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/deploy-ios.html" class="nav-list-link">Mobile objection detection on iOS</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/helpers/" class="nav-list-link">ORT Mobile Model Export Helpers</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Web category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/web/" class="nav-list-link">Web</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/build-web-app.html" class="nav-list-link">Build a web app with ONNX Runtime</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/env-flags-and-session-options.html" class="nav-list-link">The 'env' Flags and Session Options</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/ep-webgpu.html" class="nav-list-link">Using WebGPU</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/large-models.html" class="nav-list-link">Working with Large Models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/performance-diagnosis.html" class="nav-list-link">Performance Diagnosis</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/deploy.html" class="nav-list-link">Deploying ONNX Runtime Web</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/trouble-shooting.html" class="nav-list-link">Troubleshooting</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/classify-images-nextjs-github-template.html" class="nav-list-link">Classify images with ONNX Runtime and Next.js</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/excel-addin-bert-js.html" class="nav-list-link">Custom Excel Functions for BERT Tasks in JavaScript</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Deploy on IoT and edge category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/iot-edge/" class="nav-list-link">Deploy on IoT and edge</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/iot-edge/rasp-pi-cv.html" class="nav-list-link">IoT Deployment on Raspberry Pi</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/traditional-ml.html" class="nav-list-link">Deploy traditional ML</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Inference with C# category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/csharp/" class="nav-list-link">Inference with C#</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/basic_csharp.html" class="nav-list-link">Basic C# Tutorial</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/bert-nlp-csharp-console-app.html" class="nav-list-link">Inference BERT NLP with C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/csharp-gpu.html" class="nav-list-link">Configure CUDA for GPU with C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/resnet50_csharp.html" class="nav-list-link">Image recognition with ResNet50v2 in C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/stable-diffusion-csharp.html" class="nav-list-link">Stable Diffusion with C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/yolov3_object_detection_csharp.html" class="nav-list-link">Object detection in C# using OpenVINO</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/fasterrcnn_csharp.html" class="nav-list-link">Object detection with Faster RCNN in C#</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in On-Device Training category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/on-device-training/" class="nav-list-link">On-Device Training</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/on-device-training/android-app.html" class="nav-list-link">Building an Android Application</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/on-device-training/ios-app.html" class="nav-list-link">Building an iOS Application</a> </li></ul></li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/api/" class="nav-list-link">API Docs</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Build ONNX Runtime category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/build/" class="nav-list-link">Build ONNX Runtime</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/inferencing.html" class="nav-list-link">Build for inferencing</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/training.html" class="nav-list-link">Build for training</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/eps.html" class="nav-list-link">Build with different EPs</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/web.html" class="nav-list-link">Build for web</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/android.html" class="nav-list-link">Build for Android</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/ios.html" class="nav-list-link">Build for iOS</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/custom.html" class="nav-list-link">Custom build</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Generate API (Preview) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/" class="nav-list-link">Generate API (Preview)</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/tutorials/" class="nav-list-link">Tutorials</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html" class="nav-list-link">Phi-3 vision tutorial</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/tutorials/phi3-python.html" class="nav-list-link">Phi-3 tutorial</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/tutorials/phi2-python.html" class="nav-list-link">Phi-2 tutorial</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in API docs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/api/" class="nav-list-link">API docs</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/api/python.html" class="nav-list-link">Python API</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/api/csharp.html" class="nav-list-link">C# API</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/api/c.html" class="nav-list-link">C API</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in How to category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/howto/" class="nav-list-link">How to</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/install.html" class="nav-list-link">Install</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/build-from-source.html" class="nav-list-link">Build from source</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/build-model.html" class="nav-list-link">Build models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/setup-cuda-env.html" class="nav-list-link">Setup CUDA env</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reference category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/reference/" class="nav-list-link">Reference</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/reference/config.html" class="nav-list-link">Config reference</a> </li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Execution Providers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/execution-providers/" class="nav-list-link">Execution Providers</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html" class="nav-list-link">NVIDIA - CUDA</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html" class="nav-list-link">NVIDIA - TensorRT</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html" class="nav-list-link">Intel - OpenVINO™</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/oneDNN-ExecutionProvider.html" class="nav-list-link">Intel - oneDNN</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/DirectML-ExecutionProvider.html" class="nav-list-link">Windows - DirectML</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/QNN-ExecutionProvider.html" class="nav-list-link">Qualcomm - QNN</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/NNAPI-ExecutionProvider.html" class="nav-list-link">Android - NNAPI</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/CoreML-ExecutionProvider.html" class="nav-list-link">Apple - CoreML</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/Xnnpack-ExecutionProvider.html" class="nav-list-link">XNNPACK</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/ROCm-ExecutionProvider.html" class="nav-list-link">AMD - ROCm</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/MIGraphX-ExecutionProvider.html" class="nav-list-link">AMD - MIGraphX</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/Vitis-AI-ExecutionProvider.html" class="nav-list-link">AMD - Vitis AI</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/Azure-ExecutionProvider.html" class="nav-list-link">Cloud - Azure</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Community-maintained category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/" class="nav-list-link">Community-maintained</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/ACL-ExecutionProvider.html" class="nav-list-link">Arm - ACL</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/ArmNN-ExecutionProvider.html" class="nav-list-link">Arm - Arm NN</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/TVM-ExecutionProvider.html" class="nav-list-link">Apache - TVM</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/RKNPU-ExecutionProvider.html" class="nav-list-link">Rockchip - RKNPU</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/CANN-ExecutionProvider.html" class="nav-list-link">Huawei - CANN</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/add-execution-provider.html" class="nav-list-link">Add a new provider</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Extensions category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/extensions/" class="nav-list-link">Extensions</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/extensions/add-op.html" class="nav-list-link">Add Operators</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/extensions/build.html" class="nav-list-link">Build</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Performance category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/performance/" class="nav-list-link">Performance</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tune performance category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/performance/tune-performance/" class="nav-list-link">Tune performance</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/profiling-tools.html" class="nav-list-link">Profiling tools</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/logging_tracing.html" class="nav-list-link">Logging &amp; Tracing</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/memory.html" class="nav-list-link">Memory consumption</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/threading.html" class="nav-list-link">Thread management</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/iobinding.html" class="nav-list-link">I/O Binding</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/troubleshooting.html" class="nav-list-link">Troubleshooting</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Model optimizations category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/performance/model-optimizations/" class="nav-list-link">Model optimizations</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html" class="nav-list-link">Quantize ONNX models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/float16.html" class="nav-list-link">Float16 and mixed precision models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/graph-optimizations.html" class="nav-list-link">Graph optimizations</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/ort-format-models.html" class="nav-list-link">ORT model format</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/ort-format-model-runtime-optimization.html" class="nav-list-link">ORT model format runtime optimization</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/performance/transformers-optimization.html" class="nav-list-link">Transformers optimizer</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/performance/olive.html" class="nav-list-link">End to end optimization with Olive</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/performance/device-tensor.html" class="nav-list-link">Device tensors</a></li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/ecosystem/" class="nav-list-link">Ecosystem</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reference category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/reference/" class="nav-list-link">Reference</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/releases-servicing.html" class="nav-list-link">Releases</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/compatibility.html" class="nav-list-link">Compatibility</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Operators category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/reference/operators/" class="nav-list-link">Operators</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/OperatorKernels.html" class="nav-list-link">Operator kernels</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/MobileOps.html" class="nav-list-link">ORT Mobile operators</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/ContribOperators.html" class="nav-list-link">Contrib operators</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/add-custom-op.html" class="nav-list-link">Custom operators</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/reduced-operator-config-file.html" class="nav-list-link">Reduced operator config file</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/high-level-design.html" class="nav-list-link">Architecture</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/citing.html" class="nav-list-link">Citing ONNX Runtime</a></li></ul></li></ul> <ul class="nav-list"><li class="nav-list-item external"> <a href="https://github.com/microsoft/onnxruntime/tree/gh-pages" class="nav-list-link external" target="_blank" rel="noopener noreferrer"> ONNX Runtime Docs on GitHub </a> </li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search onnxruntime" aria-label="Search onnxruntime" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/" class="site-button"> ONNX Runtime </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/install/" class="site-button"> Install </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/" class="site-button"> Get Started </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/" class="site-button"> Tutorials </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/api/" class="site-button"> API Docs </a> </li> <li class="aux-nav-list-item"> <a href="https://www.youtube.com/onnxruntime" class="site-button"> YouTube </a> </li> <li class="aux-nav-list-item"> <a href="https://github.com/microsoft/onnxruntime" class="site-button"> GitHub </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1 id="install-onnx-runtime-ort"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-ort" class="anchor-heading" aria-labelledby="install-onnx-runtime-ort"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime (ORT) </h1> <p>See the <a href="https://onnxruntime.ai/">installation matrix</a> for recommended instructions for desired combinations of target operating system, hardware, accelerator, and language.</p> <p>Details on OS versions, compilers, language versions, dependent libraries, etc can be found under <a href="https://onnxruntime.ai/docs/reference/compatibility">Compatibility</a>.</p> <h2 class="no_toc" id="contents"> <a href="https://onnxruntime.ai/docs/install/#contents" class="anchor-heading" aria-labelledby="contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Contents </h2> <ul id="markdown-toc"> <li><a href="https://onnxruntime.ai/docs/install/#requirements" id="markdown-toc-requirements">Requirements</a></li> <li><a href="https://onnxruntime.ai/docs/install/#python-installs" id="markdown-toc-python-installs">Python Installs</a></li> <li><a href="https://onnxruntime.ai/docs/install/#cccwinml-installs" id="markdown-toc-cccwinml-installs">C#/C/C++/WinML Installs</a></li> <li><a href="https://onnxruntime.ai/docs/install/#install-on-web-and-mobile" id="markdown-toc-install-on-web-and-mobile">Install on web and mobile</a></li> <li><a href="https://onnxruntime.ai/docs/install/#install-for-on-device-training" id="markdown-toc-install-for-on-device-training">Install for On-Device Training</a></li> <li><a href="https://onnxruntime.ai/docs/install/#large-model-training" id="markdown-toc-large-model-training">Large Model Training</a></li> <li><a href="https://onnxruntime.ai/docs/install/#inference-install-table-for-all-languages" id="markdown-toc-inference-install-table-for-all-languages">Inference install table for all languages</a></li> <li><a href="https://onnxruntime.ai/docs/install/#training-install-table-for-all-languages" id="markdown-toc-training-install-table-for-all-languages">Training install table for all languages</a></li> </ul> <h2 id="requirements"> <a href="https://onnxruntime.ai/docs/install/#requirements" class="anchor-heading" aria-labelledby="requirements"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Requirements </h2> <ul> <li> <p>All builds require the English language package with <code class="language-plaintext highlighter-rouge">en_US.UTF-8</code> locale. On Linux, install <a href="https://packages.ubuntu.com/search?keywords=language-pack-en">language-pack-en package</a> by running <code class="language-plaintext highlighter-rouge">locale-gen en_US.UTF-8</code> and <code class="language-plaintext highlighter-rouge">update-locale LANG=en_US.UTF-8</code></p> </li> <li> <p>Windows builds require <a href="https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads">Visual C++ 2019 runtime</a>. The latest version is recommended.</p> </li> </ul> <h3 id="cuda-and-cudnn"> <a href="https://onnxruntime.ai/docs/install/#cuda-and-cudnn" class="anchor-heading" aria-labelledby="cuda-and-cudnn"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> CUDA and CuDNN </h3> <p>For ONNX Runtime GPU package, it is required to install <a href="https://developer.nvidia.com/cuda-toolkit">CUDA</a> and <a href="https://developer.nvidia.com/cudnn">cuDNN</a>. Check <a href="https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements">CUDA execution provider requirements</a> for compatible version of CUDA and cuDNN.</p> <ul> <li>cuDNN 8.x requires ZLib. Follow the <a href="https://docs.nvidia.com/deeplearning/cudnn/archives/cudnn-890/install-guide/index.html">cuDNN 8.9 installation guide</a> to install zlib in Linux or Windows. Note that the official gpu package does not support cuDNN 9.x.</li> <li>The path of CUDA bin directory must be added to the PATH environment variable.</li> <li>In Windows, the path of cuDNN bin directory must be added to the PATH environment variable.</li> </ul> <h2 id="python-installs"> <a href="https://onnxruntime.ai/docs/install/#python-installs" class="anchor-heading" aria-labelledby="python-installs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Python Installs </h2> <h3 id="install-onnx-runtime-ort-1"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-ort-1" class="anchor-heading" aria-labelledby="install-onnx-runtime-ort-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime (ORT) </h3> <h4 id="install-onnx-runtime-cpu"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-cpu" class="anchor-heading" aria-labelledby="install-onnx-runtime-cpu"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime CPU </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>onnxruntime
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="install-onnx-runtime-gpu-cuda-11x"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-gpu-cuda-11x" class="anchor-heading" aria-labelledby="install-onnx-runtime-gpu-cuda-11x"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime GPU (CUDA 11.x) </h4> <p>The default CUDA version for ORT is 11.8.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>onnxruntime-gpu
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="install-onnx-runtime-gpu-cuda-12x"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-gpu-cuda-12x" class="anchor-heading" aria-labelledby="install-onnx-runtime-gpu-cuda-12x"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime GPU (CUDA 12.x) </h4> <p>For Cuda 12.x, please use the following instructions to install from <a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/onnxruntime-cuda-12/PyPI/onnxruntime-gpu/overview">ORT Azure Devops Feed</a></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>onnxruntime-gpu <span class="nt">--extra-index-url</span> https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h3 id="install-onnx-to-export-the-model"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-to-export-the-model" class="anchor-heading" aria-labelledby="install-onnx-to-export-the-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX to export the model </h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## ONNX is built into PyTorch</span>
pip <span class="nb">install </span>torch
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## tensorflow</span>
pip <span class="nb">install </span>tf2onnx
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">## sklearn</span>
pip <span class="nb">install </span>skl2onnx
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h2 id="cccwinml-installs"> <a href="https://onnxruntime.ai/docs/install/#cccwinml-installs" class="anchor-heading" aria-labelledby="cccwinml-installs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> C#/C/C++/WinML Installs </h2> <h3 id="install-onnx-runtime-ort-2"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-ort-2" class="anchor-heading" aria-labelledby="install-onnx-runtime-ort-2"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime (ORT) </h3> <h4 id="install-onnx-runtime-cpu-1"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-cpu-1" class="anchor-heading" aria-labelledby="install-onnx-runtime-cpu-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime CPU </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># CPU</span>
dotnet add package Microsoft.ML.OnnxRuntime
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="install-onnx-runtime-gpu-cuda-11x-1"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-gpu-cuda-11x-1" class="anchor-heading" aria-labelledby="install-onnx-runtime-gpu-cuda-11x-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime GPU (CUDA 11.x) </h4> <p>The default CUDA version for ORT is 11.8</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># GPU</span>
dotnet add package Microsoft.ML.OnnxRuntime.Gpu
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="install-onnx-runtime-gpu-cuda-12x-1"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-gpu-cuda-12x-1" class="anchor-heading" aria-labelledby="install-onnx-runtime-gpu-cuda-12x-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime GPU (CUDA 12.x) </h4> <ol> <li>Project Setup</li> </ol> <p>Ensure you have installed the latest version of the Azure Artifacts keyring from the its <a href="https://github.com/microsoft/artifacts-credprovider#azure-artifacts-credential-provider">Github Repo</a>. <br> Add a nuget.config file to your project in the same directory as your .csproj file.</p> <div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span class="nt">&lt;configuration&gt;</span>
    <span class="nt">&lt;packageSources&gt;</span>
        <span class="nt">&lt;clear/&gt;</span>
        <span class="nt">&lt;add</span> <span class="na">key=</span><span class="s">"onnxruntime-cuda-12"</span>
             <span class="na">value=</span><span class="s">"https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/nuget/v3/index.json"</span><span class="nt">/&gt;</span>
    <span class="nt">&lt;/packageSources&gt;</span>
<span class="nt">&lt;/configuration&gt;</span>
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <ol> <li>Restore packages</li> </ol> <p>Restore packages (using the interactive flag, which allows dotnet to prompt you for credentials)</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dotnet add package Microsoft.ML.OnnxRuntime.Gpu
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p>Note: You don’t need –interactive every time. dotnet will prompt you to add –interactive if it needs updated credentials.</p> <h4 id="directml"> <a href="https://onnxruntime.ai/docs/install/#directml" class="anchor-heading" aria-labelledby="directml"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> DirectML </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dotnet add package Microsoft.ML.OnnxRuntime.DirectML
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="winml"> <a href="https://onnxruntime.ai/docs/install/#winml" class="anchor-heading" aria-labelledby="winml"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> WinML </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dotnet add package Microsoft.AI.MachineLearning
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h2 id="install-on-web-and-mobile"> <a href="https://onnxruntime.ai/docs/install/#install-on-web-and-mobile" class="anchor-heading" aria-labelledby="install-on-web-and-mobile"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install on web and mobile </h2> <p>Unless stated otherwise, the installation instructions in this section refer to pre-built packages that include support for selected operators and ONNX opset versions based on the requirements of popular models. These packages may be referred to as “mobile packages”. If you use mobile packages, your model must only use the supported <a href="https://onnxruntime.ai/docs/reference/operators/mobile_package_op_type_support_1.14.html">opsets and operators</a>.</p> <p>Another type of pre-built package has full support for all ONNX opsets and operators, at the cost of larger binary size. These packages are referred to as “full packages”.</p> <p>If the pre-built mobile package supports your model/s but is too large, you can create a <a href="https://onnxruntime.ai/docs/build/custom.html">custom build</a>. A custom build can include just the opsets and operators in your model/s to reduce the size.</p> <p>If the pre-built mobile package does not include the opsets or operators in your model/s, you can either use the full package if available, or create a custom build.</p> <h3 id="javascript-installs"> <a href="https://onnxruntime.ai/docs/install/#javascript-installs" class="anchor-heading" aria-labelledby="javascript-installs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> JavaScript Installs </h3> <h4 id="install-onnx-runtime-web-browsers"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-web-browsers" class="anchor-heading" aria-labelledby="install-onnx-runtime-web-browsers"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime Web (browsers) </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># install latest release version</span>
npm <span class="nb">install </span>onnxruntime-web

<span class="c"># install nightly build dev version</span>
npm <span class="nb">install </span>onnxruntime-web@dev
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="install-onnx-runtime-nodejs-binding-nodejs"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-nodejs-binding-nodejs" class="anchor-heading" aria-labelledby="install-onnx-runtime-nodejs-binding-nodejs"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime Node.js binding (Node.js) </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># install latest release version</span>
npm <span class="nb">install </span>onnxruntime-node
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="install-onnx-runtime-for-react-native"> <a href="https://onnxruntime.ai/docs/install/#install-onnx-runtime-for-react-native" class="anchor-heading" aria-labelledby="install-onnx-runtime-for-react-native"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install ONNX Runtime for React Native </h4> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># install latest release version</span>
npm <span class="nb">install </span>onnxruntime-react-native
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h3 id="install-on-ios"> <a href="https://onnxruntime.ai/docs/install/#install-on-ios" class="anchor-heading" aria-labelledby="install-on-ios"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install on iOS </h3> <p>In your CocoaPods <code class="language-plaintext highlighter-rouge">Podfile</code>, add the <code class="language-plaintext highlighter-rouge">onnxruntime-c</code>, <code class="language-plaintext highlighter-rouge">onnxruntime-mobile-c</code>, <code class="language-plaintext highlighter-rouge">onnxruntime-objc</code>, or <code class="language-plaintext highlighter-rouge">onnxruntime-mobile-objc</code> pod, depending on whether you want to use a full or mobile package and which API you want to use.</p> <h4 id="cc"> <a href="https://onnxruntime.ai/docs/install/#cc" class="anchor-heading" aria-labelledby="cc"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> C/C++ </h4> <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">use_frameworks!</span>

  <span class="c1"># choose one of the two below:</span>
  <span class="n">pod</span> <span class="s1">'onnxruntime-c'</span>  <span class="c1"># full package</span>
  <span class="c1">#pod 'onnxruntime-mobile-c'  # mobile package</span>
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h4 id="objective-c"> <a href="https://onnxruntime.ai/docs/install/#objective-c" class="anchor-heading" aria-labelledby="objective-c"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Objective-C </h4> <div class="language-ruby highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="n">use_frameworks!</span>

  <span class="c1"># choose one of the two below:</span>
  <span class="n">pod</span> <span class="s1">'onnxruntime-objc'</span>  <span class="c1"># full package</span>
  <span class="c1">#pod 'onnxruntime-mobile-objc'  # mobile package</span>
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p>Run <code class="language-plaintext highlighter-rouge">pod install</code>.</p> <h4 id="custom-build"> <a href="https://onnxruntime.ai/docs/install/#custom-build" class="anchor-heading" aria-labelledby="custom-build"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Custom build </h4> <p>Refer to the instructions for creating a <a href="https://onnxruntime.ai/docs/build/custom.html#ios">custom iOS package</a>.</p> <h3 id="install-on-android"> <a href="https://onnxruntime.ai/docs/install/#install-on-android" class="anchor-heading" aria-labelledby="install-on-android"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install on Android </h3> <h4 id="javakotlin"> <a href="https://onnxruntime.ai/docs/install/#javakotlin" class="anchor-heading" aria-labelledby="javakotlin"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Java/Kotlin </h4> <p>In your Android Studio Project, make the following changes to:</p> <ol> <li> <p>build.gradle (Project):</p> <div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">repositories</span> <span class="o">{</span>
     <span class="n">mavenCentral</span><span class="o">()</span>
 <span class="o">}</span>
</code></pre></div> <button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> </li> <li> <p>build.gradle (Module):</p> <div class="language-gradle highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">dependencies</span> <span class="o">{</span>
     <span class="c1">// choose one of the two below:</span>
     <span class="n">implementation</span> <span class="s1">'com.microsoft.onnxruntime:onnxruntime-android:latest.release'</span>  <span class="c1">// full package</span>
     <span class="c1">//implementation 'com.microsoft.onnxruntime:onnxruntime-mobile:latest.release'  // mobile package</span>
 <span class="o">}</span>
</code></pre></div> <button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> </li> </ol> <h4 id="cc-1"> <a href="https://onnxruntime.ai/docs/install/#cc-1" class="anchor-heading" aria-labelledby="cc-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> C/C++ </h4> <p>Download the <a href="https://mvnrepository.com/artifact/com.microsoft.onnxruntime/onnxruntime-android">onnxruntime-android</a> ( full package) or <a href="https://mvnrepository.com/artifact/com.microsoft.onnxruntime/onnxruntime-mobile">onnxruntime-mobile</a> ( mobile package) AAR hosted at MavenCentral, change the file extension from <code class="language-plaintext highlighter-rouge">.aar</code> to <code class="language-plaintext highlighter-rouge">.zip</code>, and unzip it. Include the header files from the <code class="language-plaintext highlighter-rouge">headers</code> folder, and the relevant <code class="language-plaintext highlighter-rouge">libonnxruntime.so</code> dynamic library from the <code class="language-plaintext highlighter-rouge">jni</code> folder in your NDK project.</p> <h4 id="custom-build-1"> <a href="https://onnxruntime.ai/docs/install/#custom-build-1" class="anchor-heading" aria-labelledby="custom-build-1"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Custom build </h4> <p>Refer to the instructions for creating a <a href="https://onnxruntime.ai/docs/build/custom.html#android">custom Android package</a>.</p> <h2 id="install-for-on-device-training"> <a href="https://onnxruntime.ai/docs/install/#install-for-on-device-training" class="anchor-heading" aria-labelledby="install-for-on-device-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Install for On-Device Training </h2> <p>Unless stated otherwise, the installation instructions in this section refer to pre-built packages designed to perform on-device training.</p> <p>If the pre-built training package supports your model but is too large, you can create a <a href="https://onnxruntime.ai/docs/build/custom.html">custom training build</a>.</p> <h3 id="offline-phase---prepare-for-training"> <a href="https://onnxruntime.ai/docs/install/#offline-phase---prepare-for-training" class="anchor-heading" aria-labelledby="offline-phase---prepare-for-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Offline Phase - Prepare for Training </h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python <span class="nt">-m</span> pip <span class="nb">install </span>cerberus flatbuffers h5py numpy&gt;<span class="o">=</span>1.16.6 onnx packaging protobuf sympy setuptools&gt;<span class="o">=</span>41.4.0
pip <span class="nb">install</span> <span class="nt">-i</span> https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ORT/pypi/simple/ onnxruntime-training-cpu
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <h3 id="training-phase---on-device-training"> <a href="https://onnxruntime.ai/docs/install/#training-phase---on-device-training" class="anchor-heading" aria-labelledby="training-phase---on-device-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Training Phase - On-Device Training </h3> <div class="table-wrapper"><table> <tbody><tr> <th>Device</th> <th>Language</th> <th>PackageName</th> <th>Installation Instructions</th> </tr> <tr> <td>Windows</td> <td>C, C++, C#</td> <!-- TODO (baijumeswani) - Update to Training link once published --> <td><a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime">Microsoft.ML.OnnxRuntime.Training</a></td> <td><pre lang="bash">dotnet add package Microsoft.ML.OnnxRuntime.Training</pre></td> </tr> <!-- <tr> <td></td> <td>Python</td> <td><a href="https://pypi.org/project/onnxruntime-training/">onnxruntime-training</a></td> <td><pre lang="bash">pip install onnxruntime-training</pre></td> </tr> --> <tr> <td>Linux</td> <td>C, C++</td> <td><a href="https://github.com/microsoft/onnxruntime/releases">onnxruntime-training-linux*.tgz</a></td> <td> <ul> <li>Download the <code>*.tgz</code> file from <a href="https://github.com/microsoft/onnxruntime/releases">here</a>.</li> <li>Extract it.</li> <li>Move and include the header files in the <code>include</code> directory.</li> <li>Move the <code>libonnxruntime.so</code> dynamic library to a desired path and include it.</li> </ul> </td> </tr> <tr> <td></td> <td>Python</td> <td><a href="https://pypi.org/project/onnxruntime-training/">onnxruntime-training</a></td> <td><pre lang="bash">pip install onnxruntime-training</pre></td> </tr> <tr> <td>Android</td> <td>C, C++</td> <td><a href="https://mvnrepository.com/artifact/com.microsoft.onnxruntime/onnxruntime-training-android">onnxruntime-training-android</a></td> <td> <ul> <li>Download the <a href="https://mvnrepository.com/artifact/com.microsoft.onnxruntime/onnxruntime-android">onnxruntime-training-android (full package)</a> AAR hosted at Maven Central.</li> <li>Change the file extension from <code>.aar</code> to <code>.zip</code>, and unzip it.</li> <li>Include the header files from the <code>headers</code> folder.</li> <li>Include the relevant <code>libonnxruntime.so</code> dynamic library from the <code>jni</code> folder in your NDK project.</li> </ul> </td> </tr> <tr> <td></td> <td>Java/Kotlin</td> <td><a href="https://mvnrepository.com/artifact/com.microsoft.onnxruntime/onnxruntime-android">onnxruntime-training-android</a></td> <td>In your Android Studio Project, make the following changes to: <ol> <li>build.gradle (Project):<pre lang="gradle">repositories {
    mavenCentral()
}
          </pre></li> <li>build.gradle (Module):<pre lang="gradle">dependencies {
    implementation 'com.microsoft.onnxruntime:onnxruntime-training-android:latest.release'
}
          </pre></li> </ol> </td> </tr> <tr> <td>iOS</td> <td>C, C++</td> <td><b>CocoaPods: onnxruntime-training-c</b></td> <td> <ul> <li>In your CocoaPods <code>Podfile</code>, add the <code>onnxruntime-training-c</code> pod:<pre>use_frameworks!
pod 'onnxruntime-training-c'
          </pre></li> <li>Run <code>pod install</code>.</li> </ul> </td> </tr> <tr> <td></td> <td> Objective-C</td> <td><b>CocoaPods: onnxruntime-training-objc</b> </td> <td> <ul> <li> In your CocoaPods <code>Podfile</code>, add the <code>onnxruntime-training-objc</code> pod:<pre>use_frameworks!
pod 'onnxruntime-training-objc'
            </pre></li> <li> Run <code>pod install</code>. </li> </ul> </td> </tr> <tr> <td>Web</td> <td> JavaScript, TypeScript</td> <td><b></b>onnxruntime-web</td> <td><pre>npm install onnxruntime-web</pre><ul> <li> Use either <code>import * as ort from 'onnxruntime-web/training';</code> or <code>const ort = require('onnxruntime-web/training');</code> </li> </ul> </td> </tr> </tbody></table></div> <h2 id="large-model-training"> <a href="https://onnxruntime.ai/docs/install/#large-model-training" class="anchor-heading" aria-labelledby="large-model-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Large Model Training </h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>torch-ort
python <span class="nt">-m</span> torch_ort.configure
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><strong>Note</strong>: This installs the default version of the <code class="language-plaintext highlighter-rouge">torch-ort</code> and <code class="language-plaintext highlighter-rouge">onnxruntime-training</code> packages that are mapped to specific versions of the CUDA libraries. Refer to the install options in <a href="https://onnxruntime.ai/">onnxruntime.ai</a>.</p> <h2 id="inference-install-table-for-all-languages"> <a href="https://onnxruntime.ai/docs/install/#inference-install-table-for-all-languages" class="anchor-heading" aria-labelledby="inference-install-table-for-all-languages"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Inference install table for all languages </h2> <p>The table below lists the build variants available as officially supported packages. Others can be <a href="https://onnxruntime.ai/docs/build/inferencing">built from source</a> from each <a href="https://github.com/microsoft/onnxruntime/tags">release branch</a>.</p> <p>In addition to general <a href="https://onnxruntime.ai/docs/install/#requirements">requirements</a>, please note additional requirements and dependencies in the table below:</p> <div class="table-wrapper"><table> <thead> <tr> <th>&nbsp;</th> <th>Official build</th> <th>Nightly build</th> <th>Reqs</th> </tr> </thead> <tbody> <tr> <td>Python</td> <td>If using pip, run <code class="language-plaintext highlighter-rouge">pip install --upgrade pip</code> prior to downloading.</td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td>&nbsp;</td> <td>CPU: <a href="https://pypi.org/project/onnxruntime"><strong>onnxruntime</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly/overview">ort-nightly (dev)</a></td> <td>&nbsp;</td> </tr> <tr> <td>&nbsp;</td> <td>GPU (CUDA/TensorRT) for CUDA 11.x: <a href="https://pypi.org/project/onnxruntime-gpu"><strong>onnxruntime-gpu</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-gpu/overview/">ort-nightly-gpu (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements">View</a></td> </tr> <tr> <td>&nbsp;</td> <td>GPU (CUDA/TensorRT) for CUDA 12.x: <a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/onnxruntime-cuda-12/PyPI/onnxruntime-gpu/overview/"><strong>onnxruntime-gpu</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ort-cuda-12-nightly/PyPI/ort-nightly-gpu/overview/">ort-nightly-gpu (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements">View</a></td> </tr> <tr> <td>&nbsp;</td> <td>GPU (DirectML): <a href="https://pypi.org/project/onnxruntime-directml/"><strong>onnxruntime-directml</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml/overview/">ort-nightly-directml (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/execution-providers/DirectML-ExecutionProvider.html#requirements">View</a></td> </tr> <tr> <td>&nbsp;</td> <td>OpenVINO: <a href="https://github.com/intel/onnxruntime/releases/latest"><strong>intel/onnxruntime</strong></a> - <em>Intel managed</em></td> <td>&nbsp;</td> <td><a href="https://onnxruntime.ai/docs/build/eps.html#openvino">View</a></td> </tr> <tr> <td>&nbsp;</td> <td>TensorRT (Jetson): <a href="https://elinux.org/Jetson_Zoo#ONNX_Runtime"><strong>Jetson Zoo</strong></a> - <em>NVIDIA managed</em></td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td>&nbsp;</td> <td>Azure (Cloud): <a href="https://pypi.org/project/onnxruntime-azure/"><strong>onnxruntime-azure</strong></a></td> <td>&nbsp;</td> <td>&nbsp;</td> </tr> <tr> <td>C#/C/C++</td> <td>CPU: <a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime"><strong>Microsoft.ML.OnnxRuntime</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_packaging?_a=feed&amp;feed=ORT-Nightly">ort-nightly (dev)</a></td> <td>&nbsp;</td> </tr> <tr> <td>&nbsp;</td> <td>GPU (CUDA/TensorRT): <a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime.gpu"><strong>Microsoft.ML.OnnxRuntime.Gpu</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_packaging?_a=feed&amp;feed=ORT-Nightly">ort-nightly (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider">View</a></td> </tr> <tr> <td>&nbsp;</td> <td>GPU (DirectML): <a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime.DirectML"><strong>Microsoft.ML.OnnxRuntime.DirectML</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/PyPI/ort-nightly-directml/overview">ort-nightly (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/execution-providers/DirectML-ExecutionProvider">View</a></td> </tr> <tr> <td>WinML</td> <td><a href="https://www.nuget.org/packages/Microsoft.AI.MachineLearning"><strong>Microsoft.AI.MachineLearning</strong></a></td> <td><a href="https://aiinfra.visualstudio.com/PublicPackages/_artifacts/feed/ORT-Nightly/NuGet/Microsoft.AI.MachineLearning/overview">ort-nightly (dev)</a></td> <td><a href="https://docs.microsoft.com/en-us/windows/ai/windows-ml/port-app-to-nuget#prerequisites">View</a></td> </tr> <tr> <td>Java</td> <td>CPU: <a href="https://search.maven.org/artifact/com.microsoft.onnxruntime/onnxruntime"><strong>com.microsoft.onnxruntime:onnxruntime</strong></a></td> <td>&nbsp;</td> <td><a href="https://onnxruntime.ai/docs/api/java">View</a></td> </tr> <tr> <td>&nbsp;</td> <td>GPU (CUDA/TensorRT): <a href="https://search.maven.org/artifact/com.microsoft.onnxruntime/onnxruntime_gpu"><strong>com.microsoft.onnxruntime:onnxruntime_gpu</strong></a></td> <td>&nbsp;</td> <td><a href="https://onnxruntime.ai/docs/api/java">View</a></td> </tr> <tr> <td>Android</td> <td><a href="https://search.maven.org/artifact/com.microsoft.onnxruntime/onnxruntime-mobile"><strong>com.microsoft.onnxruntime:onnxruntime-mobile</strong></a></td> <td>&nbsp;</td> <td><a href="https://onnxruntime.ai/docs/install/#install-on-ios">View</a></td> </tr> <tr> <td>iOS (C/C++)</td> <td>CocoaPods: <strong>onnxruntime-mobile-c</strong></td> <td>&nbsp;</td> <td><a href="https://onnxruntime.ai/docs/install/#install-on-ios">View</a></td> </tr> <tr> <td>Objective-C</td> <td>CocoaPods: <strong>onnxruntime-mobile-objc</strong></td> <td>&nbsp;</td> <td><a href="https://onnxruntime.ai/docs/install/#install-on-ios">View</a></td> </tr> <tr> <td>React Native</td> <td><a href="https://www.npmjs.com/package/onnxruntime-react-native"><strong>onnxruntime-react-native</strong> (latest)</a></td> <td><a href="https://www.npmjs.com/package/onnxruntime-react-native?activeTab=versions">onnxruntime-react-native (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/api/js">View</a></td> </tr> <tr> <td>Node.js</td> <td><a href="https://www.npmjs.com/package/onnxruntime-node"><strong>onnxruntime-node</strong> (latest)</a></td> <td><a href="https://www.npmjs.com/package/onnxruntime-node?activeTab=versions">onnxruntime-node (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/api/js">View</a></td> </tr> <tr> <td>Web</td> <td><a href="https://www.npmjs.com/package/onnxruntime-web"><strong>onnxruntime-web</strong> (latest)</a></td> <td><a href="https://www.npmjs.com/package/onnxruntime-web?activeTab=versions">onnxruntime-web (dev)</a></td> <td><a href="https://onnxruntime.ai/docs/api/js">View</a></td> </tr> </tbody> </table></div> <p><em>Note: Dev builds created from the master branch are available for testing newer changes between official releases. Please use these at your own risk. We strongly advise against deploying these to production workloads as support is limited for dev builds.</em></p> <h2 id="training-install-table-for-all-languages"> <a href="https://onnxruntime.ai/docs/install/#training-install-table-for-all-languages" class="anchor-heading" aria-labelledby="training-install-table-for-all-languages"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Training install table for all languages </h2> <p>Refer to the getting started with <a href="https://onnxruntime.ai/getting-started">Optimized Training</a> page for more fine-grained installation instructions.</p> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">For documentation questions, please <a href="https://github.com/microsoft/onnxruntime/issues/new?assignees=&amp;labels=documentation&amp;projects=&amp;template=02-documentation.yml&amp;title=%5BDocumentation%5D+" target="_blank">file an issue</a>.</p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/microsoft/onnxruntime/tree/gh-pages/docs/install/index.md" id="edit-this-page">Edit this page on GitHub</a> </p> </div> </footer> </div> </div> <div class="search-overlay"></div> </div>  
</body></html>