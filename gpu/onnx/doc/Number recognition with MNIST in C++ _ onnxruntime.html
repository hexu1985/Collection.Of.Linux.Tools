<!DOCTYPE html>
<!-- saved from url=(0052)https://onnxruntime.ai/docs/tutorials/mnist_cpp.html -->
<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">  <meta http-equiv="X-UA-Compatible" content="IE=Edge"> <link rel="stylesheet" href="./Number recognition with MNIST in C++ _ onnxruntime_files/just-the-docs-default.css"> <link rel="stylesheet" href="./Number recognition with MNIST in C++ _ onnxruntime_files/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet" disabled=""> <style id="jtd-nav-activation"> .site-nav ul li a { background-image: none; } </style> <script type="text/javascript" async="" src="./Number recognition with MNIST in C++ _ onnxruntime_files/analytics.js"></script><script type="text/javascript" async="" src="./Number recognition with MNIST in C++ _ onnxruntime_files/js"></script><script async="" src="./Number recognition with MNIST in C++ _ onnxruntime_files/js(1)"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-156955408-1'); </script> <script src="./Number recognition with MNIST in C++ _ onnxruntime_files/lunr.min.js"></script> <script src="./Number recognition with MNIST in C++ _ onnxruntime_files/just-the-docs.js"></script> <meta name="viewport" content="width=device-width, initial-scale=1"> <link rel="icon" href="https://onnxruntime.ai/favicon.ico" type="image/x-icon"> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>Number recognition with MNIST in C++ | onnxruntime</title> <meta name="generator" content="Jekyll v3.9.5"> <meta property="og:title" content="Number recognition with MNIST in C++"> <meta property="og:locale" content="en_US"> <meta name="description" content="ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator"> <meta property="og:description" content="ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator"> <link rel="canonical" href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html"> <meta property="og:url" content="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html"> <meta property="og:site_name" content="onnxruntime"> <meta property="og:type" content="website"> <meta name="twitter:card" content="summary"> <meta property="twitter:title" content="Number recognition with MNIST in C++"> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"WebPage","description":"ONNX Runtime: cross-platform, high performance ML inferencing and training accelerator","headline":"Number recognition with MNIST in C++","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://onnxruntime.ai/images/ONNX-Runtime-logo.svg"}},"url":"https://onnxruntime.ai/docs/tutorials/mnist_cpp.html"}</script> <!-- End Jekyll SEO tag --> <meta property="og:image" content="/images/logos/onnxruntime/ORT_icon_for_light_bg.png"> <script type="text/javascript" src="./Number recognition with MNIST in C++ _ onnxruntime_files/ms.analytics-web-3.min.js"></script> <script type="text/javascript"> const config = { instrumentationKey: '360b0e675e0044398fd28c8bdf711b8e-1fe5434d-ee99-4837-99cc-a3a16462d82d-7262', channelConfiguration: { eventsLimitInMem: 50 }, propertyConfiguration: { env: 'PROD' }, webAnalyticsConfiguration: { autoCapture: { scroll: true, pageView: true, onLoad: true, onUnload: true, click: true, resize: true, jsError: true } } }; const analytics = new oneDS.ApplicationInsights(); analytics.initialize(config, []); </script> </head> <body> <a class="skip-to-main" href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#main-content">Skip to main content</a> <svg xmlns="http://www.w3.org/2000/svg" class="d-none"> <symbol id="svg-link" viewBox="0 0 24 24"> <title>Link</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link"> <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path> </svg> </symbol> <symbol id="svg-menu" viewBox="0 0 24 24"> <title>Menu</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"> <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line> </svg> </symbol> <symbol id="svg-arrow-right" viewBox="0 0 24 24"> <title>Expand</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right"> <polyline points="9 18 15 12 9 6"></polyline> </svg> </symbol> <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE --> <symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link"> <title id="svg-external-link-title">(external link)</title> <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line> </symbol> <symbol id="svg-doc" viewBox="0 0 24 24"> <title>Document</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file"> <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline> </svg> </symbol> <symbol id="svg-search" viewBox="0 0 24 24"> <title>Search</title> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search"> <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line> </svg> </symbol> <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md --> <symbol id="svg-copy" viewBox="0 0 16 16"> <title>Copy</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"></path> <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"></path> </svg> </symbol> <symbol id="svg-copied" viewBox="0 0 16 16"> <title>Copied</title> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16"> <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"></path> <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"></path> </svg> </symbol> </svg> <div class="side-bar"> <div class="site-header" role="banner"> <a href="https://onnxruntime.ai/" class="site-title lh-tight"> <div class="site-logo" role="img" aria-label="onnxruntime"></div> </a> <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false"> <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg> </button> </div> <nav aria-label="Main" id="site-nav" class="site-nav"> <ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/" class="nav-list-link">ONNX Runtime</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/install/" class="nav-list-link">Install ONNX Runtime</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Get Started category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/get-started/" class="nav-list-link">Get Started</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-python.html" class="nav-list-link">Python</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-cpp.html" class="nav-list-link">C++</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-c.html" class="nav-list-link">C</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-csharp.html" class="nav-list-link">C#</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-java.html" class="nav-list-link">Java</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in JavaScript category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/get-started/with-javascript/" class="nav-list-link">JavaScript</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/with-javascript/web.html" class="nav-list-link">Web</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/with-javascript/node.html" class="nav-list-link">Node.js binding</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/with-javascript/react-native.html" class="nav-list-link">React Native</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-obj-c.html" class="nav-list-link">Objective-C</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/community-projects.html" class="nav-list-link">Julia and Ruby APIs</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-windows.html" class="nav-list-link">Windows</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/with-mobile.html" class="nav-list-link">Mobile</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/training-on-device.html" class="nav-list-link">On-Device Training</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/get-started/training-pytorch.html" class="nav-list-link">Large Model Training</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/" class="nav-list-link">Tutorials</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/api-basics.html" class="nav-list-link">API Basics</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Accelerate PyTorch category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/" class="nav-list-link">Accelerate PyTorch</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/pytorch.html" class="nav-list-link">PyTorch Inference</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/resnet-inferencing.html" class="nav-list-link">Inference on multiple targets</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/accelerate-pytorch/ort-training.html" class="nav-list-link">Accelerate PyTorch Training</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/tensorflow.html" class="nav-list-link">Accelerate TensorFlow</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/huggingface.html" class="nav-list-link">Accelerate Hugging Face</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/azureml.html" class="nav-list-link">Deploy on AzureML</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Deploy on mobile category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/mobile/" class="nav-list-link">Deploy on mobile</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/pose-detection.html" class="nav-list-link">Object detection and pose estimation with YOLOv8</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/deploy-android.html" class="nav-list-link">Mobile image recognition on Android</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/superres.html" class="nav-list-link">Improve image resolution on mobile</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/deploy-ios.html" class="nav-list-link">Mobile objection detection on iOS</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/mobile/helpers/" class="nav-list-link">ORT Mobile Model Export Helpers</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Web category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/web/" class="nav-list-link">Web</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/build-web-app.html" class="nav-list-link">Build a web app with ONNX Runtime</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/env-flags-and-session-options.html" class="nav-list-link">The 'env' Flags and Session Options</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/ep-webgpu.html" class="nav-list-link">Using WebGPU</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/large-models.html" class="nav-list-link">Working with Large Models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/performance-diagnosis.html" class="nav-list-link">Performance Diagnosis</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/deploy.html" class="nav-list-link">Deploying ONNX Runtime Web</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/trouble-shooting.html" class="nav-list-link">Troubleshooting</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/classify-images-nextjs-github-template.html" class="nav-list-link">Classify images with ONNX Runtime and Next.js</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/web/excel-addin-bert-js.html" class="nav-list-link">Custom Excel Functions for BERT Tasks in JavaScript</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Deploy on IoT and edge category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/iot-edge/" class="nav-list-link">Deploy on IoT and edge</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/iot-edge/rasp-pi-cv.html" class="nav-list-link">IoT Deployment on Raspberry Pi</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/tutorials/traditional-ml.html" class="nav-list-link">Deploy traditional ML</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Inference with C# category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/csharp/" class="nav-list-link">Inference with C#</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/basic_csharp.html" class="nav-list-link">Basic C# Tutorial</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/bert-nlp-csharp-console-app.html" class="nav-list-link">Inference BERT NLP with C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/csharp-gpu.html" class="nav-list-link">Configure CUDA for GPU with C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/resnet50_csharp.html" class="nav-list-link">Image recognition with ResNet50v2 in C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/stable-diffusion-csharp.html" class="nav-list-link">Stable Diffusion with C#</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/yolov3_object_detection_csharp.html" class="nav-list-link">Object detection in C# using OpenVINO</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/csharp/fasterrcnn_csharp.html" class="nav-list-link">Object detection with Faster RCNN in C#</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in On-Device Training category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/tutorials/on-device-training/" class="nav-list-link">On-Device Training</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/on-device-training/android-app.html" class="nav-list-link">Building an Android Application</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/on-device-training/ios-app.html" class="nav-list-link">Building an iOS Application</a> </li></ul></li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/api/" class="nav-list-link">API Docs</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Build ONNX Runtime category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/build/" class="nav-list-link">Build ONNX Runtime</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/inferencing.html" class="nav-list-link">Build for inferencing</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/training.html" class="nav-list-link">Build for training</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/eps.html" class="nav-list-link">Build with different EPs</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/web.html" class="nav-list-link">Build for web</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/android.html" class="nav-list-link">Build for Android</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/ios.html" class="nav-list-link">Build for iOS</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/build/custom.html" class="nav-list-link">Custom build</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Generate API (Preview) category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/" class="nav-list-link">Generate API (Preview)</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tutorials category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/tutorials/" class="nav-list-link">Tutorials</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html" class="nav-list-link">Phi-3 vision tutorial</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/tutorials/phi3-python.html" class="nav-list-link">Phi-3 tutorial</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/tutorials/phi2-python.html" class="nav-list-link">Phi-2 tutorial</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in API docs category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/api/" class="nav-list-link">API docs</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/api/python.html" class="nav-list-link">Python API</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/api/csharp.html" class="nav-list-link">C# API</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/api/c.html" class="nav-list-link">C API</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in How to category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/howto/" class="nav-list-link">How to</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/install.html" class="nav-list-link">Install</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/build-from-source.html" class="nav-list-link">Build from source</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/build-model.html" class="nav-list-link">Build models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/howto/setup-cuda-env.html" class="nav-list-link">Setup CUDA env</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reference category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/genai/reference/" class="nav-list-link">Reference</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/genai/reference/config.html" class="nav-list-link">Config reference</a> </li></ul></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Execution Providers category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/execution-providers/" class="nav-list-link">Execution Providers</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html" class="nav-list-link">NVIDIA - CUDA</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/TensorRT-ExecutionProvider.html" class="nav-list-link">NVIDIA - TensorRT</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/OpenVINO-ExecutionProvider.html" class="nav-list-link">Intel - OpenVINO™</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/oneDNN-ExecutionProvider.html" class="nav-list-link">Intel - oneDNN</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/DirectML-ExecutionProvider.html" class="nav-list-link">Windows - DirectML</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/QNN-ExecutionProvider.html" class="nav-list-link">Qualcomm - QNN</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/NNAPI-ExecutionProvider.html" class="nav-list-link">Android - NNAPI</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/CoreML-ExecutionProvider.html" class="nav-list-link">Apple - CoreML</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/Xnnpack-ExecutionProvider.html" class="nav-list-link">XNNPACK</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/ROCm-ExecutionProvider.html" class="nav-list-link">AMD - ROCm</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/MIGraphX-ExecutionProvider.html" class="nav-list-link">AMD - MIGraphX</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/Vitis-AI-ExecutionProvider.html" class="nav-list-link">AMD - Vitis AI</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/Azure-ExecutionProvider.html" class="nav-list-link">Cloud - Azure</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Community-maintained category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/" class="nav-list-link">Community-maintained</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/ACL-ExecutionProvider.html" class="nav-list-link">Arm - ACL</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/ArmNN-ExecutionProvider.html" class="nav-list-link">Arm - Arm NN</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/TVM-ExecutionProvider.html" class="nav-list-link">Apache - TVM</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/RKNPU-ExecutionProvider.html" class="nav-list-link">Rockchip - RKNPU</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/execution-providers/community-maintained/CANN-ExecutionProvider.html" class="nav-list-link">Huawei - CANN</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/execution-providers/add-execution-provider.html" class="nav-list-link">Add a new provider</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Extensions category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/extensions/" class="nav-list-link">Extensions</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/extensions/add-op.html" class="nav-list-link">Add Operators</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/extensions/build.html" class="nav-list-link">Build</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Performance category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/performance/" class="nav-list-link">Performance</a><ul class="nav-list"><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Tune performance category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/performance/tune-performance/" class="nav-list-link">Tune performance</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/profiling-tools.html" class="nav-list-link">Profiling tools</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/logging_tracing.html" class="nav-list-link">Logging &amp; Tracing</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/memory.html" class="nav-list-link">Memory consumption</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/threading.html" class="nav-list-link">Thread management</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/iobinding.html" class="nav-list-link">I/O Binding</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/tune-performance/troubleshooting.html" class="nav-list-link">Troubleshooting</a> </li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Model optimizations category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/performance/model-optimizations/" class="nav-list-link">Model optimizations</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html" class="nav-list-link">Quantize ONNX models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/float16.html" class="nav-list-link">Float16 and mixed precision models</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/graph-optimizations.html" class="nav-list-link">Graph optimizations</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/ort-format-models.html" class="nav-list-link">ORT model format</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/performance/model-optimizations/ort-format-model-runtime-optimization.html" class="nav-list-link">ORT model format runtime optimization</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/performance/transformers-optimization.html" class="nav-list-link">Transformers optimizer</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/performance/olive.html" class="nav-list-link">End to end optimization with Olive</a></li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/ecosystem/" class="nav-list-link">Ecosystem</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Reference category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/reference/" class="nav-list-link">Reference</a><ul class="nav-list"><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/releases-servicing.html" class="nav-list-link">Releases</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/compatibility.html" class="nav-list-link">Compatibility</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Operators category" aria-pressed="false"> <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg> </button><a href="https://onnxruntime.ai/docs/reference/operators/" class="nav-list-link">Operators</a><ul class="nav-list"><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/OperatorKernels.html" class="nav-list-link">Operator kernels</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/MobileOps.html" class="nav-list-link">ORT Mobile operators</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/ContribOperators.html" class="nav-list-link">Contrib operators</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/add-custom-op.html" class="nav-list-link">Custom operators</a> </li><li class="nav-list-item"> <a href="https://onnxruntime.ai/docs/reference/operators/reduced-operator-config-file.html" class="nav-list-link">Reduced operator config file</a> </li></ul></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/high-level-design.html" class="nav-list-link">Architecture</a></li><li class="nav-list-item"><a href="https://onnxruntime.ai/docs/reference/citing.html" class="nav-list-link">Citing ONNX Runtime</a></li></ul></li></ul> <ul class="nav-list"><li class="nav-list-item external"> <a href="https://github.com/microsoft/onnxruntime/tree/gh-pages" class="nav-list-link external" target="_blank" rel="noopener noreferrer"> ONNX Runtime Docs on GitHub </a> </li></ul> </nav> <footer class="site-footer"> This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll. </footer> </div> <div class="main" id="top"> <div id="main-header" class="main-header"> <div class="search" role="search"> <div class="search-input-wrap"> <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search onnxruntime" aria-label="Search onnxruntime" autocomplete="off"> <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label> </div> <div id="search-results" class="search-results"></div> </div> <nav aria-label="Auxiliary" class="aux-nav"> <ul class="aux-nav-list"> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/" class="site-button"> ONNX Runtime </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/install/" class="site-button"> Install </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/get-started/" class="site-button"> Get Started </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/tutorials/" class="site-button"> Tutorials </a> </li> <li class="aux-nav-list-item"> <a href="https://onnxruntime.ai/docs/api/" class="site-button"> API Docs </a> </li> <li class="aux-nav-list-item"> <a href="https://www.youtube.com/onnxruntime" class="site-button"> YouTube </a> </li> <li class="aux-nav-list-item"> <a href="https://github.com/microsoft/onnxruntime" class="site-button"> GitHub </a> </li> </ul> </nav> </div> <div class="main-content-wrap"> <div id="main-content" class="main-content"> <main> <h1 class="no_toc" id="number-recognition-with-mnist-in-c"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#number-recognition-with-mnist-in-c" class="anchor-heading" aria-labelledby="number-recognition-with-mnist-in-c"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Number recognition with MNIST in C++ </h1> <p>This sample uses the MNIST model from the Model Zoo: https://github.com/onnx/models/tree/main/validated/vision/classification/mnist</p> <p><img src="./Number recognition with MNIST in C++ _ onnxruntime_files/mnist-screenshot.png" alt="Screenshot"></p> <h2 class="no_toc" id="contents"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#contents" class="anchor-heading" aria-labelledby="contents"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Contents </h2> <ul id="markdown-toc"> <li><a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#requirements" id="markdown-toc-requirements">Requirements</a></li> <li><a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#build" id="markdown-toc-build">Build</a></li> <li><a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#how-to-use-it" id="markdown-toc-how-to-use-it">How to use it</a></li> <li><a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#how-it-works" id="markdown-toc-how-it-works">How it works</a></li> </ul> <h2 id="requirements"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#requirements" class="anchor-heading" aria-labelledby="requirements"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Requirements </h2> <p>Compiled Onnxruntime.dll / lib (link to instructions on how to build dll) Windows Visual Studio Compiler (cl.exe)</p> <h2 id="build"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#build" class="anchor-heading" aria-labelledby="build"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Build </h2> <p>Run ‘build.bat’ in this directory to call cl.exe to generate MNIST.exe Then just run MNIST.exe</p> <h2 id="how-to-use-it"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#how-to-use-it" class="anchor-heading" aria-labelledby="how-to-use-it"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How to use it </h2> <p>Just draw a number with the left mouse button (or use touch) in the box on the left side. After releasing the mouse button the model will be run and the outputs of the model will be displayed. Note that when drawing numbers requiring multiple drawing strokes, the model will be run at the end of each stroke with probably wrong predictions (but it’s amusing to see and avoids needing to press a ‘run model’ button).</p> <p>To clear the image, click the right mouse button anywhere.</p> <h2 id="how-it-works"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#how-it-works" class="anchor-heading" aria-labelledby="how-it-works"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> How it works </h2> <p>A single Ort::Env is created globally to initialize the runtime.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Ort::Env env{ORT_LOGGING_LEVEL_WARNING, "test"};
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L12">[Source]</a></p> <p>The MNIST structure abstracts away all of the interaction with the Onnx Runtime, creating the tensors, and running the model.</p> <p>WWinMain is the Windows entry point, it creates the main window.</p> <p>WndProc is the window procedure for the window, handling the mouse input and drawing the graphics</p> <h3 id="preprocessing-the-data"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#preprocessing-the-data" class="anchor-heading" aria-labelledby="preprocessing-the-data"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Preprocessing the data </h3> <p>MNIST’s input is a {1,1,28,28} shaped float tensor, which is basically a 28x28 floating point grayscale image (0.0 = background, 1.0 = foreground).</p> <p>The sample stores the image in a 32-bit per pixel windows DIB section, since that’s easy to draw into and draw to the screen for windows. The DIB is created here:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> {
    BITMAPINFO bmi{};
    bmi.bmiHeader.biSize = sizeof(bmi.bmiHeader);
    bmi.bmiHeader.biWidth = MNIST::width_;
    bmi.bmiHeader.biHeight = -MNIST::height_;
    bmi.bmiHeader.biPlanes = 1;
    bmi.bmiHeader.biBitCount = 32;
    bmi.bmiHeader.biPlanes = 1;
    bmi.bmiHeader.biCompression = BI_RGB;

    void* bits;
    dib_ = CreateDIBSection(nullptr, &amp;bmi, DIB_RGB_COLORS, &amp;bits, nullptr, 0);
  }
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L109-L121">[Source]</a></p> <p>The function to convert the DIB data and writ it into the model’s input tensor:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>void ConvertDibToMnist() {
  DIBInfo info{dib_};

  const DWORD* input = reinterpret_cast&lt;const DWORD*&gt;(info.Bits());
  float* output = mnist_.input_image_.data();

  std::fill(mnist_.input_image_.begin(), mnist_.input_image_.end(), 0.f);

  for (unsigned y = 0; y &lt; MNIST::height_; y++) {
    for (unsigned x = 0; x &lt; MNIST::width_; x++) {
      output[x] += input[x] == 0 ? 1.0f : 0.0f;
    }
    input = reinterpret_cast&lt;const DWORD*&gt;(reinterpret_cast&lt;const BYTE*&gt;(input) + info.Pitch());
  }
  output += MNIST::width_;
}
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L77-L92">[Source]</a></p> <h3 id="postprocessing-the-output"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#postprocessing-the-output" class="anchor-heading" aria-labelledby="postprocessing-the-output"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Postprocessing the output </h3> <p>MNIST’s output is a simple {1,10} float tensor that holds the likelihood weights per number. The number with the highest value is the model’s best guess.</p> <p>The MNIST structure uses std::max_element to do this and stores it in result_:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>result_ = std::distance(results_.begin(), std::max_element(results_.begin(), results_.end()));
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L31">[Source]</a></p> <p>To make things more interesting, the window painting handler graphs the probabilities and shows the weights here:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> // Hilight the winner
      RECT rc{graphs_left, mnist_.result_ * 16, graphs_left + graph_width + 128, (mnist_.result_ + 1) * 16};
      FillRect(hdc, &amp;rc, brush_winner_);

      // For every entry, draw the odds and the graph for it
      SetBkMode(hdc, TRANSPARENT);
      wchar_t value[80];
      for (unsigned i = 0; i &lt; 10; i++) {
        int y = 16 * i;
        float result = mnist_.results_[i];

        auto length = wsprintf(value, L"%2d: %d.%02d", i, int(result), abs(int(result * 100) % 100));
        TextOut(hdc, graphs_left + graph_width + 5, y, value, length);

        Rectangle(hdc, graphs_zero, y + 1, graphs_zero + result * graph_width / range, y + 14);
      }

      // Draw the zero line
      MoveToEx(hdc, graphs_zero, 0, nullptr);
      LineTo(hdc, graphs_zero, 16 * 10);
</code></pre></div><button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L164-L183">[Source]</a></p> <h3 id="the-ortsession"> <a href="https://onnxruntime.ai/docs/tutorials/mnist_cpp.html#the-ortsession" class="anchor-heading" aria-labelledby="the-ortsession"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> The Ort::Session </h3> <ol> <li>Creation: The Ort::Session is created inside the MNIST structure here: <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">Ort</span><span class="o">::</span><span class="n">Session</span> <span class="n">session_</span><span class="p">{</span><span class="n">env</span><span class="p">,</span> <span class="n">ORT_TSTR</span><span class="p">(</span><span class="s">"model.onnx"</span><span class="p">),</span> <span class="n">Ort</span><span class="o">::</span><span class="n">SessionOptions</span><span class="p">{</span><span class="nb">nullptr</span><span class="p">}};</span>
</code></pre></div> <button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L43">[Source]</a></p> </li> <li>Setup inputs &amp; outputs: The input &amp; output tensors are created here: <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="n">MNIST</span><span class="p">()</span> <span class="p">{</span>
 <span class="k">auto</span> <span class="n">allocator_info</span> <span class="o">=</span> <span class="n">Ort</span><span class="o">::</span><span class="n">AllocatorInfo</span><span class="o">::</span><span class="n">CreateCpu</span><span class="p">(</span><span class="n">OrtDeviceAllocator</span><span class="p">,</span> <span class="n">OrtMemTypeCPU</span><span class="p">);</span>
 <span class="n">input_tensor_</span> <span class="o">=</span> <span class="n">Ort</span><span class="o">::</span><span class="n">Value</span><span class="o">::</span><span class="n">CreateTensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">allocator_info</span><span class="p">,</span> <span class="n">input_image_</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">input_image_</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">input_shape_</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">input_shape_</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
 <span class="n">output_tensor_</span> <span class="o">=</span> <span class="n">Ort</span><span class="o">::</span><span class="n">Value</span><span class="o">::</span><span class="n">CreateTensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="n">allocator_info</span><span class="p">,</span> <span class="n">results_</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">results_</span><span class="p">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">output_shape_</span><span class="p">.</span><span class="n">data</span><span class="p">(),</span> <span class="n">output_shape_</span><span class="p">.</span><span class="n">size</span><span class="p">());</span>
 <span class="p">}</span>
</code></pre></div> <button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L19-L23">[Source]</a></p> <p>In this usage, we’re providing the memory location for the data instead of having Ort allocate the buffers. This is simpler in this case since the buffers are small and can just be fixed members of the MNIST struct.</p> </li> <li>Run: Running the session is done in the Run() method: <div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="kt">int</span> <span class="nf">Run</span><span class="p">()</span> <span class="p">{</span>
 <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">input_names</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Input3"</span><span class="p">};</span>
 <span class="k">const</span> <span class="kt">char</span><span class="o">*</span> <span class="n">output_names</span><span class="p">[]</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Plus214_Output_0"</span><span class="p">};</span>

 <span class="n">session_</span><span class="p">.</span><span class="n">Run</span><span class="p">(</span><span class="n">Ort</span><span class="o">::</span><span class="n">RunOptions</span><span class="p">{</span><span class="nb">nullptr</span><span class="p">},</span> <span class="n">input_names</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">input_tensor_</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">output_names</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">output_tensor_</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>

 <span class="n">result_</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">distance</span><span class="p">(</span><span class="n">results_</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">std</span><span class="o">::</span><span class="n">max_element</span><span class="p">(</span><span class="n">results_</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">results_</span><span class="p">.</span><span class="n">end</span><span class="p">()));</span>
 <span class="k">return</span> <span class="n">result_</span><span class="p">;</span>
 <span class="p">}</span>
</code></pre></div> <button type="button" aria-label="Copy code to clipboard"><svg viewBox="0 0 24 24" class="copy-icon"><use xlink:href="#svg-copy"></use></svg></button></div> <p><a href="https://github.com/microsoft/onnxruntime/blob/521dc757984fbf9770d0051997178fbb9565cd52/samples/c_cxx/MNIST/MNIST.cpp#L25-L33">[Source]</a></p> </li> </ol> </main> <hr> <footer> <p class="text-small text-grey-dk-100 mb-0">For documentation questions, please <a href="https://github.com/microsoft/onnxruntime/issues/new?assignees=&amp;labels=documentation&amp;projects=&amp;template=02-documentation.yml&amp;title=%5BDocumentation%5D+" target="_blank">file an issue</a>.</p> <div class="d-flex mt-2"> <p class="text-small text-grey-dk-000 mb-0"> <a href="https://github.com/microsoft/onnxruntime/tree/gh-pages/docs/tutorials/mnist_cpp.md" id="edit-this-page">Edit this page on GitHub</a> </p> </div> </footer> </div> </div> <div class="search-overlay"></div> </div>  
</body></html>